{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile,isdir, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv1D, Dropout,Activation,MaxPooling1D,Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86565a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allX = []\n",
    "allY = []\n",
    "maxi=0.\n",
    "mini=0.\n",
    "count=0\n",
    "\n",
    "\n",
    "path0=\"./BASE DE DATOS\"  #estos son datos de encefalogramas \n",
    "\n",
    "carpetas = [ f for f in listdir(path0) if isdir(join(path0,f))]\n",
    "carpetas_f = [ k for k in carpetas if 'Data_F' in k]\n",
    "carpetas_n = [ k for k in carpetas if 'Data_N' in k]\n",
    "print(carpetas)\n",
    "print(carpetas_f)\n",
    "print(carpetas_n)\n",
    "for d in carpetas_f:\n",
    "    path = join(path0,d)\n",
    "    files = [ f for f in listdir(path)]\n",
    "    for f in files:\n",
    "        serie = []\n",
    "        with open(join(path,f), newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            for row in spamreader:\n",
    "                serie.append(float(row[0]))\n",
    "        fserie = np.abs(fft(serie))\n",
    "        allX.append(fserie)\n",
    "        allY.append(0)\n",
    "        max_tmp=max(serie)\n",
    "        if (max_tmp > maxi):\n",
    "            maxi = max_tmp\n",
    "        min_tmp=min(serie)\n",
    "print(len(allX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b1d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi=0.\n",
    "mini=0.\n",
    "for d in carpetas_n:\n",
    "    path = join(path0,d)\n",
    "    files = [ f for f in listdir(path)]\n",
    "    for f in files:\n",
    "        serie = []\n",
    "        with open(join(path,f), newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            for row in spamreader:\n",
    "                serie.append(float(row[0]))\n",
    "        fserie = np.abs(fft(serie))\n",
    "        allX.append(fserie)\n",
    "        allY.append(1)\n",
    "        max_tmp=max(serie)\n",
    "        if (max_tmp > maxi):\n",
    "            maxi = max_tmp\n",
    "        min_tmp=min(serie)\n",
    "        if (min_tmp < mini):\n",
    "            mini = min_tmp\n",
    "        count+=1\n",
    "print(count)\n",
    "allX = np.array(allX)\n",
    "allY = np.array(allY)\n",
    "allX = (allX - mini)/(maxi - mini)\n",
    "x_train, x_test, y_train, y_test = train_test_split(allX, allY, test_size=0.3, random_state=1)\n",
    "n_patterns = len(x_train)\n",
    "seq_length = 10240\n",
    "x_train = np.reshape(x_train, (n_patterns, seq_length, 1))\n",
    "n_patterns_test = len(x_test)\n",
    "x_test = np.reshape(x_test, (n_patterns_test, seq_length, 1))\n",
    "print(n_patterns_test)\n",
    "print(x_test[2,:,0])\n",
    "print(\"----\")\n",
    "print(y_test)\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fab480",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#primera capa: convolucional de 1D con 10 filtros y 30 de ventana\n",
    "model.add(Conv1D(10, 30, input_shape=(10240,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#segunda capa convolucional 1D ignorada\n",
    "# model.add(Conv1D(10,  15))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#segunda capa convolucional 1D \n",
    "model.add(Conv1D(20, 15))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "#aplanamos los datos de forma que pasemos de convolucional a capa densa\n",
    "model.add(Flatten())\n",
    "\n",
    "#tercera capa densa de 64 neuronas \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "#capa de salida binaria\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#compilamos el modelo con la funcion de costo de cross entropy para binaria y el optimizador \"RMSprop\" \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9523756",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./electroGraph1D', histogram_freq=0, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20918e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,batch_size=100,epochs=30,verbose=1,callbacks=[tbCallBack],validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
